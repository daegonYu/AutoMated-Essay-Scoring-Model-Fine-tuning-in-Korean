경로 : .vscode , asap.ini

배치사이즈, 에폭, 모델 저장한 models 폴더


models 1,2,3
에폭 20 실험 
weight_decay = 0.05
bias : 7
loss : a=2;b=1;c=1

models 1,2,3 이어서 실험
60 에폭 => 해당 실험 결과가 models/ 4,5,6  
bias : 7
weight_decay = 0.01 
loss : a=2;b=1;c=1

models 7,8,9
bias : 2
weight_decay = 0.05
loss : a=1;b=1;c=1

models 10,11,12 -> models/ 4,5,6 에서 epochs 20 추가 진행
weight_decay = 0.05
loss : a=2;b=1;c=1

2/13
13~
bigbird 램 용량 부족
bigbird 사용을 위해 max_input_length 다 4096으로 변경함 (3군데)
+ 모델, 토크나이저 bigbird로 변경
배치사이즈 1로 변경

2/13
klue bert로 돌려놈

models 13~ : 풍부함 모델 학습


고려사항

* kobigbird : transformers.BigBirdConfig(max_position_embeddings=1024) -> 브랜치 나누기 아니면 코드에 KLUE_BERT인지 BigBird인지 나눠서 돌아가게끔 하면 되는데 건들게 많다. -> 브랜치 나누자.

1. AdamW / Adam + lr scheduler로 바꿔보기 -> RAdam으로 바꿔보기 // 에폭 2단위로 나눠서 validation -> loss, pearson, qwk 그래프 확인하기
: AdamW는 여기서 local optima에 걸리는듯? 나중에 전부 3으로 예측해버린다..
: Adam + lr scheduler는 나름 잘 학습한다. lr scheduler가 있어야 lr이 점점 작아지면서 optima에 도달할 수 있다.

: RAdam은 lr을 자동으로 찾아주는 역할을 한다. 원래 lr warmup을 통해 했었다. 이건 휴리스틱하게 정해줘야 되는 불편함이 있는데 그것을 개선한 것이다.
+ 그럼 RAdam에 lr scheduler를 추가해야하나? -> No! RAdam의 Loss 그래프를 보니 lr 스케줄러는 필요없을 듯 하다.
그래프를 보니 RAdam이나 Adam + lr 스케줄러가 잘 학습되는 것 같다. 

Adam + lr 스케줄러하고 전에 했던 거 하고 성능 비교해보기


2. 로스 함수 계수 변경해보며 성능평가하기 -> 하이퍼파라미터 찾기
: 
    # 데이터 특성에 따라 손실함수를 변경할 필요가 있다. 
    # MSE : QWK와 관련, COSSIM : pearson와 관련
    # batch size가 작고 정답값은 3이 많이 분포하므로 COSSIM는 1에 가까워지고 예측 값도 1에 가까워지려고 다 비슷해지는 것 같다. 따라서 COSSIM 삭제
    실험할 계수 = [3,0,1]

=> 이번에도 그래프 이상하면 Adam + lr 스케줄러로 가야겠다. => Adam + lr 스케줄러와 RAdam은 비슷하다.

pearson 하고 qwk 평가지표 의미 알아보기
: pearson이 높다는 건 정답 값이 올라갈 땐 올라가고 내려갈 땐 내려가는데 qwk가 높아야 4점이 4점다운 점수가 나오고 2점이 2점다운 점수가 나온다.
즉, 어느정도의 pearson이 확보되면  qwk가 좀 더 중요하다.

3. 5 fold validation 적용하기 16 epoch씩 5번 총 80에폭 (O)

실험할 계수 = [3,1,2]   // 평균 eval 비교, 똑같은 걸로 한번 더 실험중 평가의 일관성 보려고


4. 엑셀 방사형 차트 그리기(matplotlib radar chart) (O)

+ train loss와 eval loss와 성능지표(pearson, qwk)간의 상관관계 알아보기

5. 다 정리되면 성능 얼마나 올랐는지 정리해서 깃 리드미에 올리기
각각의 성능비교 : pearson과 qwk의 최대값(교차검증의 경우 평균)